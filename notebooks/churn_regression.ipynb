{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Title: Customer Churn Prediction (MySQL + Logistic Regression)\n",
    "\n",
    "Objective: Train a logistic regression model to predict customer churn, write predicted probabilities back to MySQL, and export a CSV for visualization (e.g., Tableau)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 0. Environment & Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\"Set database credentials in a .env file (not tracked in git). See .env.example for structure.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  # IMPORTANT: allows replacing a previously-set value\n",
    "import os\n",
    "\n",
    "load_dotenv()  # reads .env if present\n",
    "\n",
    "MYSQL_HOST = os.getenv(\"MYSQL_HOST\", \"127.0.0.1\")\n",
    "MYSQL_PORT = int(os.getenv(\"MYSQL_PORT\", \"3306\"))\n",
    "MYSQL_USER = os.getenv(\"MYSQL_USER\", \"root\")\n",
    "MYSQL_PASSWORD = os.getenv(\"MYSQL_PASSWORD\")  # keep secrets out of notebook\n",
    "MYSQL_DB = os.getenv(\"MYSQL_DB\", \"churn_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector as mc\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "QUERY = \"\"\"\n",
    "SELECT\n",
    "  customerID AS id,\n",
    "  is_monthly,\n",
    "  auto_pay,\n",
    "  CASE WHEN tenure < 12 THEN 1 ELSE 0 END AS short_tenure,\n",
    "  churn\n",
    "FROM customers_clean;\n",
    "\"\"\"\n",
    "\n",
    "conn = mc.connect(\n",
    "    host=os.getenv(\"MYSQL_HOST\",\"127.0.0.1\"),\n",
    "    port=int(os.getenv(\"MYSQL_PORT\",\"3306\")),\n",
    "    user=os.getenv(\"MYSQL_USER\"),\n",
    "    password=os.getenv(\"MYSQL_PASSWORD\"),\n",
    "    database=os.getenv(\"MYSQL_DB\",\"churn_project\")\n",
    ")\n",
    "df = pd.read_sql(QUERY, conn)\n",
    "conn.close()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 1) EDA sanity checks\n",
    "\n",
    "Goal: quick data validation from customers_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "print(df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "# Basic label balance\n",
    "df['churn'].value_counts().rename_axis('label').to_frame('count')\n",
    "df['churn'].value_counts(normalize=True).mul(100).round(2).rename('pct')\n",
    "\n",
    "# Leakage check: make sure target not in features\n",
    "set(df.columns) - {'id','is_monthly','auto_pay','short_tenure','churn'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2) Baseline logistic regression\n",
    "\n",
    "Goal: simple baseline using the three engineered features we already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X = df[['is_monthly','auto_pay','short_tenure']].astype(float)\n",
    "y = df['churn'].astype(int)\n",
    "ids = df['id'].astype(str)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te, id_tr, id_te = train_test_split(\n",
    "    X, y, ids, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('logreg', LogisticRegression(max_iter=2000, solver='lbfgs', class_weight=None))\n",
    "]).fit(X_tr, y_tr)\n",
    "\n",
    "p_tr = pipe.predict_proba(X_tr)[:,1]\n",
    "p_te = pipe.predict_proba(X_te)[:,1]\n",
    "\n",
    "print(f\"AUC train: {roc_auc_score(y_tr, p_tr):.3f}\")\n",
    "print(f\"AUC test : {roc_auc_score(y_te, p_te):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Step 3: One-hot encode categoricals\n",
    "Goal: lift performance by adding SQL columns and one-hot in sklearn.\n",
    "\n",
    "Categorical features like contract type and payment method canâ€™t be used directly in regression models, so we convert them into binary indicators using one-hot encoding. This allows the model to capture differences across categories without assuming any numeric order. Adding these features should improve performance compared with the simple baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PLUS = \"\"\"\n",
    "SELECT\n",
    "  customerID AS id,\n",
    "  is_monthly, auto_pay,\n",
    "  CASE WHEN tenure < 12 THEN 1 ELSE 0 END AS short_tenure,\n",
    "  Contract, PaymentMethod, gender, age_group,\n",
    "  tenure, MonthlyCharges,\n",
    "  churn\n",
    "FROM customers_clean;\n",
    "\"\"\"\n",
    "conn = mc.connect(\n",
    "    host=os.getenv(\"MYSQL_HOST\"), port=int(os.getenv(\"MYSQL_PORT\")),\n",
    "    user=os.getenv(\"MYSQL_USER\"), password=os.getenv(\"MYSQL_PASSWORD\"),\n",
    "    database=os.getenv(\"MYSQL_DB\")\n",
    ")\n",
    "df2 = pd.read_sql(QUERY_PLUS, conn); conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Step 4: ROC, Precision-Recall, and Classification Report\n",
    "\n",
    "To understand model performance beyond accuracy, we use ROC and Precision-Recall curves. ROC shows how well the model separates churners from non-churners at different thresholds, summarized by AUC. Precision-Recall is especially useful with imbalanced data, highlighting tradeoffs between catching churners (recall) and avoiding false alarms (precision).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, classification_report\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_te, p_te)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(); plt.plot(fpr,tpr,label=f\"AUC={roc_auc:.3f}\"); plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\"); plt.legend(); plt.show()\n",
    "\n",
    "# PR\n",
    "prec, rec, _ = precision_recall_curve(y_te, p_te)\n",
    "ap = average_precision_score(y_te, p_te)\n",
    "plt.figure(); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall\"); plt.legend(); plt.show()\n",
    "\n",
    "# Default 0.5 report\n",
    "y_hat = (p_te >= 0.5).astype(int)\n",
    "print(classification_report(y_te, y_hat, digits=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Step 5: Threshold Tuning and Confusion Matrix\n",
    "After choosing a threshold, we can visualize the confusion matrix to better understand errors.  \n",
    "The matrix shows true negatives, false positives, false negatives, and true positives, giving a clear picture of model tradeoffs at the chosen cutoff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def pick_threshold(p, y, target_recall=0.70):\n",
    "    prec, rec, thr = precision_recall_curve(y, p)\n",
    "    # thr has len-1 vs prec/rec; align\n",
    "    thr = np.r_[0, thr]\n",
    "    idx = np.where(rec >= target_recall)[0][-1] if np.any(rec >= target_recall) else np.argmax(rec)\n",
    "    return float(thr[idx]), float(prec[idx]), float(rec[idx])\n",
    "\n",
    "thr, pr_at_thr, rc_at_thr = pick_threshold(p_te, y_te, target_recall=0.70)\n",
    "print(f\"Chosen threshold: {thr:.3f} (precision={pr_at_thr:.3f}, recall={rc_at_thr:.3f})\")\n",
    "\n",
    "y_hat = (p_te >= thr).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, y_hat).ravel()\n",
    "print({\"tp\":tp,\"fp\":fp,\"fn\":fn,\"tn\":tn})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(y_te, y_hat)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Predicted: No churn\", \"Predicted: Churn\"],\n",
    "            yticklabels=[\"Actual: No churn\", \"Actual: Churn\"])\n",
    "plt.title(f\"Confusion Matrix (threshold={thr:.2f})\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (churn-wsl)",
   "language": "python",
   "name": "churn-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
